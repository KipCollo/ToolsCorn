# PODS

Kubernetes doesn’t deal with individual containers directly. Instead, it uses the concept of multiple co-located containers. This group of containers is called a Pod.Containers are not managed individually; instead, they are part of a larger object called a Pod. A Pod consists of one or more containers which share an IP address, access to storage and namespace. Typically, one container in a Pod runs an application, while other containers support the primary application.

A pod is a group of one or more tightly related containers that will always run together on the same worker node and in the same Linux namespace(s). Each pod
is like a separate logical machine with its own IP, hostname, processes, and so on, running a single application. The application can be a single process, running in a
single container, or it can be a main application process and additional supporting processes, each running in its own container. All the containers in a pod will appear
to be running on the same logical machine, whereas containers in other pods, even if they’re running on the same worker node, will appear to be running on a different one.

A pod is a co-located group of containers and represents the basic building block in Kubernetes.Instead of deploying containers individually,you always deploy and operate on a pod of containers. We’re not implying that a pod always includes more than one container—it’s common for pods to contain only a single container. The key thing about pods is that when a pod does contain multiple containers, all of them are always run on a single worker node—it never spans multiple worker nodes.

The key thing about pods is that when a pod does contain multiple containers, all of them are always run on a single worker node—it never spans multiple worker nodes

It contains only a single container, but generally a pod can contain as many containers as you want,storage resources,unique IP and options to govern how container(s) run.The pod has its own unique private IP address and hostname.

Pods are ephemeral and disposable,they never self-heal and not restarted by scheduler.It includes the states:- Pending,Running,Succeeded,Failed,CrashLoopBackOff.

Because you can’t list individual containers, since they’re not standalone Kubernetes objects, you can list pods instead:-

```bash
kubectl get pods
```

To see more information about the pod, you can also use the kubectl describe pod command:-

```bash
kubectl describe pods
```

The shared context of a Pod is a set of Linux namespaces, cgroups, and potentially other facets of isolation - the same things that isolate a container. Within a Pod's context, the individual applications may have further sub-isolations applied.

A Pod is similar to a set of containers with shared namespaces and shared filesystem volumes.

Pods in a Kubernetes cluster are used in two main ways:

1. Pods that run a single container. The "one-container-per-Pod" model is the most common Kubernetes use case; in this case, you can think of a Pod as a wrapper around a single container; Kubernetes manages Pods rather than managing the containers directly.
2. Pods that run multiple containers that need to work together. A Pod can encapsulate an application composed of multiple co-located containers that are tightly coupled and need to share resources. These co-located containers form a single cohesive unit.

Grouping multiple co-located and co-managed containers in a single Pod is a relatively advanced use case. You should use this pattern only in specific instances in which your containers are tightly coupled.
You don't need to run multiple containers to provide replication (for resilience or capacity); if you need multiple replicas, see Workload management



The whole point of Kubernetes is to orchestrate the life cycle of a container. We do not interact with particular containers. Instead, the smallest unit we can work with is a Pod. Some would say a pod of whales or peas-in-a-pod. Due to shared resources, the design of a Pod typically follows a one-process-per-container architecture.

Containers in a Pod are started in parallel by default. As a result, there is no way to determine which container becomes available first inside a Pod. initContainers can be used to ensure some containers are ready before others in a pod. To support a single process running in a container, you may need logging, a proxy, or special adapter. These tasks are often handled by other containers in the same Pod.

There is only one IP address per Pod with most network plugins. HPE Labs created a plugin which allows more than one IP per pod. As a result, if there is more than one container, they must share the IP. To communicate with each other, they can use IPC, the loopback interface, or a shared filesystem.

While Pods are often deployed with one application container in each, a common reason to have multiple containers in a Pod is for logging. You may find the term sidecar for a container dedicated to performing a helper task, like handling logs and responding to requests, as the primary application container may not have this ability.

Pods and other objects can be created in several ways. They can be created by using run:

```bash
$ kubectl run newpod --image=nginx
```

Or, they can be created and deleted using properly formatted JSON or YAML files:

```bash
$ kubectl create -f newpod.yaml

$ kubectl delete -f newpod.yaml
```

Other objects will be created by operators/watch-loops to ensure the specifications and current status are the same.

## Single IP per Pod

A Pod represents a group of co-located containers with some associated data volumes. All containers in a Pod share the same network namespace.
To communicate with each other, containers can use the loopback interface, write to files on a common filesystem, or via inter-process communication (IPC). As a result, co-locating applications in the same pod may have issues. There is a network plugin which will allow more than one IP address, but so far, it has only been used within HPE labs.

Support for dual-stack, IPv4 and IPv6 continues to increase with each release. For example, in a recent release kube-proxy iptables supports both stacks simultaneously.

A Pod is a group of co-located containers that share the same IP address. From a networking perspective, a Pod can be seen as a virtual machine of physical hosts. The network needs to assign IP addresses to Pods, and needs to provide traffic routes between all Pods on any nodes.

The three main networking challenges to solve in a container orchestration system are:

1. Coupled container-to-container communications (solved by the Pod concept)
2. Pod-to-Pod communications
3. External-to-Pod communications.

Kubernetes expects the network configuration to enable Pod-to-Pod communications to be available; it will not do it for you.

Pods are assigned an IP address prior to application containers being started. The service object is used to connect Pods within the network using ClusterIP addresses, from outside of the cluster using NodePort addresses, and using a load balancer if configured with a LoadBalancer service.

## Components Involved in Controlling Network Traffic

ClusterIP

A ClusterIP is used for traffic within the cluster. A NodePort first creates a ClusterIP, then associates a port of the node to that new ClusterIP. If you create a LoadBalancer service, it will first create a ClusterIP, then a NodePort, and then make an asynchronous request for an external load balancer. If one is not configured to respond, the EXTERNAL-IP will remain in a pending state for the life of the service.

 Ingress Controller or Service Mesh

An Ingress Controller or a service mesh like Istio can also be used to connect traffic to a Pod.

The diagram below shows a multi-container Pod, two services with one for internal traffic only, and an ingress controller. The sidecar container, acting as a logger, is shown writing out storage, just to show a more complete Pod. The pause container, which is only used to retrieve the namespaces and IP addresses.

Calico Pod

Another possible view of a cluster with multiple Pods 